{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"측면, 정면 비교 분석.ipynb","provenance":[],"authorship_tag":"ABX9TyMoU+Hkc7R3uV8RpEjOgDT6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install mediapipe"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uIrV695yBPaf","executionInfo":{"status":"ok","timestamp":1658042273986,"user_tz":-540,"elapsed":7918,"user":{"displayName":"김민영","userId":"07698273349272569714"}},"outputId":"2ab284a5-30f0-4c90-f41b-87fb8f6bc604"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting mediapipe\n","  Downloading mediapipe-0.8.10.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32.9 MB)\n","\u001b[K     |████████████████████████████████| 32.9 MB 1.2 MB/s \n","\u001b[?25hRequirement already satisfied: protobuf<4,>=3.11 in /usr/local/lib/python3.7/dist-packages (from mediapipe) (3.17.3)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mediapipe) (3.2.2)\n","Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.7/dist-packages (from mediapipe) (4.1.2.30)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from mediapipe) (1.1.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mediapipe) (1.21.6)\n","Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.7/dist-packages (from mediapipe) (21.4.0)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<4,>=3.11->mediapipe) (1.15.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (3.0.9)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (1.4.3)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (2.8.2)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->mediapipe) (4.1.1)\n","Installing collected packages: mediapipe\n","Successfully installed mediapipe-0.8.10.1\n"]}]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":232},"id":"VkFNT_1FA0bx","executionInfo":{"status":"error","timestamp":1658042996148,"user_tz":-540,"elapsed":312,"user":{"displayName":"김민영","userId":"07698273349272569714"}},"outputId":"a1af687d-6497-4c1b-e122-169f5f313208"},"outputs":[{"output_type":"error","ename":"error","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-d2c1cd31aa11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# 작업 전에 BGR 이미지를 RGB로 변환합니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mcon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_detection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# 이미지를 출력하고 그 위에 얼굴 박스를 그립니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31merror\u001b[0m: OpenCV(4.1.2) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"]}],"source":["import cv2\n","import mediapipe as mp\n","import pandas as pd\n","mp_face_detection = mp.solutions.face_detection\n","mp_drawing = mp.solutions.drawing_utils\n","\n","img = '/content/drive/MyDrive/AI_study/측면.png'\n","img2 = '/content/drive/MyDrive/AI_study/정면.png'\n","# 이미지 파일의 경우 이것을 사용하세요:\n","IMAGE_FILES = []\n","IMAGE_FILES.append(img)\n","IMAGE_FILES.append(img2)\n","\n","\n","with mp_face_detection.FaceDetection(\n","    model_selection=1, min_detection_confidence=0.5) as face_detection:\n","  for idx, file in enumerate(IMAGE_FILES):\n","    image = cv2.imread(file)\n","    # 작업 전에 BGR 이미지를 RGB로 변환합니다.\n","\n","    con = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","    results = face_detection.process(con)\n","\t# 이미지를 출력하고 그 위에 얼굴 박스를 그립니다.\n","    if not results.detections:\n","      continue\n","    annotated_image = image.copy()\n","    for detection in results.detections:\n","      KeyPoint = []\n","\n","      KeyPoint.append(mp_face_detection.get_key_point(\n","          detection, mp_face_detection.FaceKeyPoint.LEFT_EAR_TRAGION))\n","      KeyPoint.append(mp_face_detection.get_key_point(\n","          detection, mp_face_detection.FaceKeyPoint.LEFT_EYE))\n","      KeyPoint.append(mp_face_detection.get_key_point(\n","          detection, mp_face_detection.FaceKeyPoint.RIGHT_EAR_TRAGION))\n","      KeyPoint.append(mp_face_detection.get_key_point(\n","          detection, mp_face_detection.FaceKeyPoint.RIGHT_EYE))\n","      KeyPoint.append(mp_face_detection.get_key_point(\n","          detection, mp_face_detection.FaceKeyPoint.MOUTH_CENTER))\n","      KeyPoint.append(mp_face_detection.get_key_point(\n","          detection, mp_face_detection.FaceKeyPoint.NOSE_TIP))\n","    \n","      mp_drawing.draw_detection(annotated_image, detection)\n","    keyindex = ['LEFT_EAR_TRAGION','LEFT_EYE', 'RIGHT_EAR_TRAGION', 'RIGHT_EYE', 'MOUTH_CENTER',  'NOSE_TIP']\n","    df=pd.DataFrame(KeyPoint, index=keyindex)\n","    print(df)\n","\n","    # df.to_csv('/content/drive/MyDrive/AI_syudy/keypoints.csv')\n","    \n","    # for i, keypoint in enumerate(KeyPoint):\n","    #   print(keypoint)\n","    # print(KeyPoint)\n","    \n","    cv2.imwrite('/content/drive/MyDrive/AI_study/annotated_image' + str(idx) + '.png', annotated_image)"]}]}