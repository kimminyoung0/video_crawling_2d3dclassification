{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"face_detection.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1xBGmYiLx3-DuKFHmGxCtP4rOfACb9gcC","authorship_tag":"ABX9TyM35G7ktw6rXTRaVWM/Wo1S"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install mediapipe"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rC3xvjsy2s4X","executionInfo":{"status":"ok","timestamp":1658679733323,"user_tz":-540,"elapsed":9843,"user":{"displayName":"김민영","userId":"07698273349272569714"}},"outputId":"7dd480b7-c87f-44d1-d374-a03f0eaf3708"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting mediapipe\n","  Downloading mediapipe-0.8.10.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32.9 MB)\n","\u001b[K     |████████████████████████████████| 32.9 MB 253 kB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mediapipe) (1.21.6)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from mediapipe) (1.2.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mediapipe) (3.2.2)\n","Requirement already satisfied: protobuf<4,>=3.11 in /usr/local/lib/python3.7/dist-packages (from mediapipe) (3.17.3)\n","Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.7/dist-packages (from mediapipe) (21.4.0)\n","Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.7/dist-packages (from mediapipe) (4.6.0.66)\n","Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<4,>=3.11->mediapipe) (1.15.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (1.4.4)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (2.8.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (3.0.9)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->mediapipe) (4.1.1)\n","Installing collected packages: mediapipe\n","Successfully installed mediapipe-0.8.10.1\n"]}]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Uq6ymTss2NUT","executionInfo":{"status":"ok","timestamp":1658680016445,"user_tz":-540,"elapsed":2219,"user":{"displayName":"김민영","userId":"07698273349272569714"}},"outputId":"1c075380-27ad-4075-e2ef-aaab73cf3d85"},"outputs":[{"output_type":"stream","name":"stdout","text":["detect x\n"]}],"source":["import cv2\n","import mediapipe as mp\n","import pandas as pd\n","mp_face_detection = mp.solutions.face_detection\n","mp_drawing = mp.solutions.drawing_utils\n","\n","img = '/content/drive/MyDrive/opencv_study/안녕자두야.png'\n","# 이미지 파일의 경우 이것을 사용하세요:\n","IMAGE_FILES = []\n","IMAGE_FILES.append(img)\n","\n","with mp_face_detection.FaceDetection(\n","    model_selection=1, min_detection_confidence=0.5) as face_detection:\n","  for idx, file in enumerate(IMAGE_FILES):\n","    image = cv2.imread(file)\n","    # 작업 전에 BGR 이미지를 RGB로 변환합니다.\n","    results = face_detection.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n","\t# 이미지를 출력하고 그 위에 얼굴 박스를 그립니다.\n","    if not results.detections:\n","      print('detect x')\n","      continue\n","    annotated_image = image.copy()\n","    for detection in results.detections:\n","      KeyPoint = []\n","\n","      KeyPoint.append(mp_face_detection.get_key_point(\n","          detection, mp_face_detection.FaceKeyPoint.LEFT_EAR_TRAGION))\n","      KeyPoint.append(mp_face_detection.get_key_point(\n","          detection, mp_face_detection.FaceKeyPoint.LEFT_EYE))\n","      KeyPoint.append(mp_face_detection.get_key_point(\n","          detection, mp_face_detection.FaceKeyPoint.RIGHT_EAR_TRAGION))\n","      KeyPoint.append(mp_face_detection.get_key_point(\n","          detection, mp_face_detection.FaceKeyPoint.RIGHT_EYE))\n","      KeyPoint.append(mp_face_detection.get_key_point(\n","          detection, mp_face_detection.FaceKeyPoint.MOUTH_CENTER))\n","      KeyPoint.append(mp_face_detection.get_key_point(\n","          detection, mp_face_detection.FaceKeyPoint.NOSE_TIP))\n","    \n","      mp_drawing.draw_detection(annotated_image, detection)\n","    keyindex = ['LEFT_EAR_TRAGION','LEFT_EYE', 'RIGHT_EAR_TRAGION', 'RIGHT_EYE', 'MOUTH_CENTER',  'NOSE_TIP']\n","    df=pd.DataFrame(KeyPoint, index=keyindex)\n","    print(df)\n","\n","    df.to_csv('/content/drive/MyDrive/AI_syudy/keypoints.csv')\n","    # for i, keypoint in enumerate(KeyPoint):\n","    #   print(keypoint)\n","    # print(KeyPoint)\n","    \n","    #cv2.imwrite('/content/drive/MyDrive/AI_study/annotated_image' + str(idx) + '.png', annotated_image)"]},{"cell_type":"code","source":["import cv2\n","import mediapipe as mp\n","import pandas as pd\n","mp_face_detection = mp.solutions.face_detection\n","mp_drawing = mp.solutions.drawing_utils\n","\n","img = '/content/drive/MyDrive/opencv_study/CROP_2D_02.png' #무적코털 보보보 얼굴 감지 되는지 확인차\n","# 이미지 파일의 경우 이것을 사용하세요:\n","IMAGE_FILES = []\n","IMAGE_FILES.append(img)\n","\n","with mp_face_detection.FaceDetection(\n","    model_selection=1, min_detection_confidence=0.5) as face_detection:\n","  for idx, file in enumerate(IMAGE_FILES):\n","    image = cv2.imread(file)\n","    # 작업 전에 BGR 이미지를 RGB로 변환합니다.\n","    results = face_detection.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n","\t# 이미지를 출력하고 그 위에 얼굴 박스를 그립니다.\n","    if not results.detections:\n","      print(\"얼굴검출 x\")\n","      continue\n","    annotated_image = image.copy()\n","    for detection in results.detections:\n","      KeyPoint = []\n","\n","      KeyPoint.append(mp_face_detection.get_key_point(\n","          detection, mp_face_detection.FaceKeyPoint.LEFT_EAR_TRAGION))\n","      KeyPoint.append(mp_face_detection.get_key_point(\n","          detection, mp_face_detection.FaceKeyPoint.LEFT_EYE))\n","      KeyPoint.append(mp_face_detection.get_key_point(\n","          detection, mp_face_detection.FaceKeyPoint.RIGHT_EAR_TRAGION))\n","      KeyPoint.append(mp_face_detection.get_key_point(\n","          detection, mp_face_detection.FaceKeyPoint.RIGHT_EYE))\n","      KeyPoint.append(mp_face_detection.get_key_point(\n","          detection, mp_face_detection.FaceKeyPoint.MOUTH_CENTER))\n","      KeyPoint.append(mp_face_detection.get_key_point(\n","          detection, mp_face_detection.FaceKeyPoint.NOSE_TIP))\n","    \n","      mp_drawing.draw_detection(annotated_image, detection)\n","    keyindex = ['LEFT_EAR_TRAGION','LEFT_EYE', 'RIGHT_EAR_TRAGION', 'RIGHT_EYE', 'MOUTH_CENTER',  'NOSE_TIP']\n","    df=pd.DataFrame(KeyPoint, index=keyindex)\n","    print(df)\n","\n","    df.to_csv('/content/drive/MyDrive/AI_syudy/keypoints.csv')\n","    # for i, keypoint in enumerate(KeyPoint):\n","    #   print(keypoint)\n","    # print(KeyPoint)\n","    \n","    cv2.imwrite('/content/drive/MyDrive/opencv_study/annotated_image' + str(idx) + '.png', annotated_image)"],"metadata":{"id":"2UVWPmyf_Yy_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658492279687,"user_tz":-540,"elapsed":1005,"user":{"displayName":"김민영","userId":"07698273349272569714"}},"outputId":"30ee4386-c33b-486f-b68e-8db002f88b6b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["얼굴검출 x\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"37FBYEdX2ZqI"},"execution_count":null,"outputs":[]}]}